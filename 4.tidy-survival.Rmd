---
title: "Tidy survival"
author: "Chunyi Wu and Andrzej Galecki"
date: "`r as.character(Sys.Date(), format = '%A %B %d, %Y')`"
output:
  rmdformats::readthedown:
    lightbox: true
    use_bookdown: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment="#>")
```

```{r, data, echo=FALSE, message=FALSE, warning=FALSE}
if (!require('pacman')) install.packages('pacman', repos = "http://cran.us.r-project.org")
library(pacman)

pacman::p_load(
  readxl,       # load excel file
  glmnet,       # Lasso and Elastic-Net Regularized Generalized Linear Models
  rmdformats,   # rmd formats
  rmarkdown,    # rmarkdown
  here,         # File locator
  skimr,        # get overview of data
  tidyverse,    # data management + ggplot2 graphics 
  tidymodels,   # for the recipes package, along with the rest of tidymodels
  janitor,      # adding totals and percents to tables
  flextable,    # format the output table
  gtsummary,    # calculate summary statistics and format the results
  sjPlot,       # correlation matrix
  purrr,        # enhances R functional programming (FP) toolki 
  tidyr,        # Tools to help to create tidy data
  ggplot2,      # Plot the results
  glmnetUtils,  # glmnet models for multiple alpha
  coefplot,     # Plotting Model Coefficients
  survival,
  censored,
  dplyr
  )
```


In this report we consider penalized survival Cox regression model M2 for the `futime` variable.
`status` (0/1) variable indicates whether FU_TIME is censored or not. (0 is censored) 

* M2 :Contains 21 proteins,  Baseline HbA1c), log10(ACR), eGFR, sex and age as candidate covariates

Analysis is preformed based on:

https://parsnip.tidymodels.org/reference/details_proportional_hazards_glmnet.html




# Read Data


## Original data

* `data_orig`  contains all variables from the original data
* `data_all`   original variable names are preserved (except `FU_TIME` and `CASE_CONTROL`. 
* Factors for selected variables are created. 

```{r, readxl-data-orig}
#read the data that is stored under the datain folder

xlsx_path = "./datain/test_data053122.xlsx"
data_orig <- readxl::read_excel(xlsx_path, na = "", guess_max = 1000)

dim(data_orig)

# Vectors with variable names in `data_orig` 
prot_nms <- c(
 "KIM1.npx",       "SYND1.npx",   "IL.1RT1.npx", "WFDC2.npx", "CD27.npx", 
 "TNFRSF10A.npx",  "LAYN.npx",    "PVRL4.npx",   "EDA2R.npx", "TNFRSF4.npx", 
 "GFR_alpha_1_npx","TNF.R1.npx",  "PI3_npx",     "EFNA4.npx", "TNF.R2.npx",
 "DLL1.npx",       "TNFRSF6B.npx","CD160.npx",   "EPHA2.npx", "RELT.npx",
 "LTBR.npx")
 
cvarx1 <- c("B_HBA1C_PRC", "DU_ACR", "BL_eGFR", "SEX", "AGE_TL") 

cvarx2  <- c("SBP_TL", "DBP_TL", "AGEONSET_TL", "BMI_TL" ) 
orig_tvars <- c("CASE_CONTROL", "FU_TIME")

orig_vars <- c("INDEX", orig_tvars, cvarx1, cvarx2, prot_nms)

data_all <- data_orig  %>%  
  select(all_of(orig_vars)) %>%
  mutate(SEX = factor(SEX), INDEX= factor(INDEX)) %>% 
  rename (., status = CASE_CONTROL, futime = FU_TIME) # rename variables
```

## Analytical data

```{r Data-analytical}

# clinical covariates
cvars <- replace(cvarx1, cvarx1 %in% c("DU_ACR"), "log10_ACR")

anl_vars <- c("futime", "status", cvars, prot_nms)
  
data_anl  <- data_all %>%
  mutate (log10_ACR= log10(DU_ACR)) %>%
  select(all_of(anl_vars))
```

## Descriptive statistics

```{r data-anl-summ}
dim(data_anl)
# colnames(data_anl)   
glimpse(data_anl)
```


```{r skim-data-anl}
data_anl %>% 
  group_by(status) %>%
  skimr::skim(futime, SEX, BL_eGFR, B_HBA1C_PRC, log10_ACR)
```

# Preparatory steps

## Resampling data

Resampling data is done in preparation for cross-validation.

First, we perform initial split of the entire dataset. 

```{r initial-split}
set.seed(123)
data_splits <- rsample::initial_split(data_anl, prop=0.8)
```

In this analysis, we use _all_ data for model training, because for model testing we will use 
external data. 

```{r data-train}
data_train <- data_anl   ## training(splits)
data_test_init  <- testing(data_splits)
```

We split the training dataset for cross-validation (CV)

```{r val-set}
set.seed(234)
val_set <- vfold_cv(data_train, v=10)
class(val_set)
val_set
```

## Preparing recipe

This section is included for illustration only. 

https://www.tidymodels.org/start/recipes/#recipe

* Recipe defines the transformations that must be applied to the _training_ data before fitting.
* The recipe also defines the formula that will be fitted by the models???
* Pre-processing applied using recipe needs to happen _inside_ the cross-validation loop, not outside of it

Initiate new recipe. 
Unfortunately, recipe is not implemented for coxnet model.


```{r survdata-recipe-init}
dt_template <- data_all %>% slice(0)
colnms <- colnames(dt_template)
surv_recp_init <-
  recipe(dt_template) %>%
    update_role(all_of(colnms), new_role = "predictor") %>%
    update_role(DBP_TL, SBP_TL, AGEONSET_TL, BMI_TL, new_role = "_OMIT_") %>%
    update_role(INDEX,   new_role = "ID") %>%
    update_role(futime,  new_role = "outcome") %>%
    update_role(status,  new_role = "status")  %>%
    step_dummy(all_nominal_predictors()) %>% 
    step_zv(all_predictors()) %>% 
    step_normalize(all_predictors())
 surv_recp_init   
```
 
 From: https://www.tidymodels.org/start/case-study/#first-model
 
 * `step_dummy()` converts characters or factors (i.e., nominal variables) into one or more numeric binary model terms for the levels of the original data.
 * `step_zv()` removes indicator variables that only contain a single unique value (e.g. all zeros). This is important because, for penalized models, the predictors should be centered and scaled.
 * `step_normalize()` centers and scales numeric variables.
 

# Penalized Cox regression (alpha is known)

https://parsnip.tidymodels.org/reference/glmnet-details.html#tidying-the-model-object

## Model spec

Model specification is performed by calling `proportional_hazards function`.
In a default call `penalty` argument is set to a _constant_.

* this constant will be used for _prediction_ only.
* ... and will _not_ be passed to a call to `glmnet`. 
* Instead, full path will be fit by `glmnet()`


The model is defined as follows:

```{r surv-mod-default}
# PH default
surv_mod <- proportional_hazards(
    penalty = 0.7,  # This value will be used for prediction.
    mixture = 0.5) %>% 
    set_engine("glmnet") %>% 
    set_mode("censored regression")
class(surv_mod)
surv_mod  %>%  translate()
```

The code chunk below illustrates how to declare user-defined sequence of lambdas . This sequence
will be passed to `glmnet()` call.


```{r surv-mod-manual}
# PH manual
coef_path_values <- c(0, 10^seq(-5, 1, length.out = 7))
surv_mod_manual <- proportional_hazards(
    penalty = 0.7,     # This value will be used for prediction.
    mixture = 0.5) %>% 
    set_engine("glmnet", path_values = coef_path_values) %>% 
    set_mode("censored regression")
surv_mod_manual  %>%  translate()
```



## Model fit

https://censored.tidymodels.org/articles/examples.html

```{r surv-fit-formula}
surv_fit <- surv_mod %>% 
    fit(Surv(futime, status) ~ . , data = data_train)
glance(surv_fit)
tidy(surv_fit)
```

Extract beta coefficients for a selected lambda (identified by `step` variable.

```{r extract-estimates-1model}
tidy(surv_fit) %>% filter(step == 10)

```


```{r surv-fit}
pred_survival <- predict(surv_fit, data_test_init, type= "survival", time = c(3,6,9,12))
pred_time  <- predict(surv_fit, data_test_init, type= "time")
Surv_obs <- Surv(data_test_init$futime, data_test_init$status)
cbind(Surv_obs, pred_time)
```

# Penalized cox regression (alpha unknown)


## Model definition

Note: Defined model contains two hyper-parameters:

https://www.tidymodels.org/start/case-study/#first-model

https://www.jkangpathology.com/post/tidymodel-and-glmnet/

https://dials.tidymodels.org/articles/Basics.html

https://www.brodrigues.co/blog/2020-03-08-tidymodels/

We define three objects:

1. the model itself: `surv_tune_mod`
2. a grid of hyper-parameters: `surv_grid`
3. a workflow: `surv_workflow_init`

1. We define proportional hazards (PH) model with two hyperparameters: penalty (lambda), mixture(alpha))

```{r surv-tune-mod}
# PH
surv_tune_mod <- proportional_hazards(
    penalty = tune(), mixture = tune() ) %>% 
    set_engine("glmnet")
class(surv_tune_mod)
surv_tune_mod  %>%  translate()
```

2. Hyperparametric grid


```{r hyperparametric-grid}
surv_grid <- surv_tune_mod %>%  
        parameters(list(lambda = penalty(), alpha = mixture())) %>%
        grid_regular(levels=c(5,3))
class(surv_grid)
surv_grid
```

3. Create the model workflow

```{r surv-workflow-init}  
surv_workflow_init <- 
  workflow() %>% 
  add_model(surv_tune_mod)
```

```{r surv-wf-recp}
surv_wf_recp2 <- surv_workflow_init %>%  
    add_recipe(surv_recp2)
class(surv_workflow0)
surv_workflow0
```


## Fitting model

Using model formula:

```{r fitted-model}
form <- Surv(futime,status) ~ SEX + AGE_TL 
fitted_wflow <- fit(surv_workflow0, data = data_train)
```





## Train and tune the model

https://www.tidyverse.org/blog/2021/11/survival-analysis-parsnip-adjacent/

```{r surv-workflow}  
surv_workflow <- surv_workflow0 %>%
    tune_grid(val_set,
              preprocessor = surv_recp2,
              grid =  tune_grid_dt,
              control = control_grid(save_pred = TRUE),
              metrics = metric_set(roc_auc))

```


formula <-  Surv(futime, status) ~ SEX + AGE_TL
fit(surv_mod, formula, data_all)

glmnet_set <- parameters(list(lambda = penalty(), alpha = mixture()))

glmnet_set2 <- update(glmnet_set, alpha = mixture(c(.3, .6)))
glmnet_set2
